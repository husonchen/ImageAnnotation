{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sps\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sqlite3 as lite \n",
    "from bidict import bidict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[    0.,  8332.,     0., ...,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0., ...,     0.,     0.,     0.],\n",
       "        [ 3169.,  5925.,     0., ...,     0.,     0.,     0.],\n",
       "        ..., \n",
       "        [    0.,     0.,     0., ...,     0.,     0.,     0.],\n",
       "        [    0.,     0.,     0., ...,     0.,     0.,     0.],\n",
       "        [    0.,   591.,     0., ...,     0.,     0.,     0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = lite.connect('G:\\\\ImageAnnotation\\\\python\\\\SNAPCoocFull.db')\n",
    "con.text_factory = lambda x: str(x, \"utf-8\", \"ignore\")\n",
    "cur = con.cursor()\n",
    "cur.execute('select * from edges limit 1000')\n",
    "dbrows = cur.fetchall()\n",
    "\n",
    "# change string to int data\n",
    "wordEntry=bidict({})\n",
    "wordCount = 0\n",
    "for i in range(1000):\n",
    "    if dbrows[i][0] not in wordEntry:\n",
    "        wordEntry[dbrows[i][0]] = wordCount\n",
    "        wordCount += 1\n",
    "    if dbrows[i][1] not in wordEntry:\n",
    "        wordEntry[dbrows[i][1]] = wordCount\n",
    "        wordCount += 1\n",
    "print(str(wordCount))\n",
    "row = np.zeros(1000)\n",
    "col = np.zeros(1000)\n",
    "data = np.zeros(1000)\n",
    "for i in range(1000):\n",
    "    row[i] = wordEntry[dbrows[i][0]]\n",
    "    col[i] = wordEntry[dbrows[i][1]]\n",
    "    data[i] = dbrows[i][2]\n",
    "mtx = sps.csr_matrix((data, (row, col)), shape=(wordCount, wordCount))\n",
    "mtx.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
